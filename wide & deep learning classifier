"""Example code for TensorFlow Wide & Deep Tutorial using TF.Learn API."""
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function
import tempfile
import pandas as pd
import tensorflow as tf
from sklearn.model_selection import train_test_split
import time
from sklearn import metrics

start = time.process_time()

print('---------------loading data -------------------')
df = pd.read_csv(r'F:\sepctra_data\wide_deep_data\光度级\3classes.csv')
data = df.iloc[:, 1:]
labels = df.iloc[:, 0]
traindata, testdata, trainlabels, testlabels = train_test_split(data, labels, test_size=0.2, random_state=1)
print('------------------ done ----------------------')

print('----------creating feature columns ------------')
# deep 部分，所有光谱
csv_columns = [df.columns[i] for i in range(1, 3902)]
deep_colunms = []
for col_name in csv_columns:
    col_name = tf.feature_column.numeric_column(col_name)
    deep_colunms.append(col_name)


# wide部分特征处理
# 巨星矮星
# Na I(a)
NaIa_band = deep_colunms[894:918]
NaIa_conti = deep_colunms[1344:1355]
NaIa = []
for col in NaIa_band:
    col = tf.feature_column.bucketized_column(col, boundaries=[0.2, 0.4, 0.6, 0.8])
    NaIa.append(col)
for col in NaIa_conti:
    col = tf.feature_column.bucketized_column(col, boundaries=[0.2, 0.4, 0.6, 0.8])
    NaIa.append(col)

# Na I(b)
NaIb_band = deep_colunms[3182:3197]
NaIb_conti = deep_colunms[3169:3173]
NaIb_conti.extend(deep_colunms[3231:3235])
NaIb_conti.extend(deep_colunms[3116:3119])
NaIb = []
for col in NaIb_band:
    col = tf.feature_column.bucketized_column(col, boundaries=[0.2, 0.4, 0.6, 0.8])
    NaIb.append(col)
for col in NaIb_conti:
    col = tf.feature_column.bucketized_column(col, boundaries=[0.2, 0.4, 0.6, 0.8])
    NaIb.append(col)

# K I
KI_band = deep_colunms[2668:2705]
KI_conti = deep_colunms[2676:2691]
KI_conti.extend(deep_colunms[2801:2825])
KI = []
for col in KI_band:
    col = tf.feature_column.bucketized_column(col, boundaries=[0.2, 0.4, 0.6, 0.8])
    KI.append(col)
for col in KI_conti:
    col = tf.feature_column.bucketized_column(col, boundaries=[0.2, 0.4, 0.6, 0.8])
    KI.append(col)

# CaII
CaII_band = deep_colunms[3539:3662]
CaII_conti = deep_colunms[3249:3300]
CaII_conti.extend(deep_colunms[3569:3600])
CaII = []
for col in CaII_band:
    col = tf.feature_column.bucketized_column(col, boundaries=[0.2, 0.4, 0.6, 0.8])
    CaII.append(col)
for col in CaII_conti:
    col = tf.feature_column.bucketized_column(col, boundaries=[0.2, 0.4, 0.6, 0.8])
    CaII.append(col)

# CaH、TiO5、B、Mgb
CaH_band = deep_colunms[1813:1846]
CaH_band.extend(deep_colunms[1901:1904])
CaH_band.extend(deep_colunms[1917:1920])
CaH_band.extend(deep_colunms[1959:1990])
TiO5_band = deep_colunms[2125:2135]
B_band = deep_colunms[1497:1499]
B_band.extend(deep_colunms[1562:1566])
Mgb_band = deep_colunms[167:170]
CaH_conti = deep_colunms[2041:2046]
CaH = []
TiO5 = []
B = []
Mgb = []
for col in CaH_band:
    col = tf.feature_column.bucketized_column(col, boundaries=[0.2, 0.4, 0.6, 0.8])
    CaH.append(col)
for col in TiO5_band:
    col = tf.feature_column.bucketized_column(col, boundaries=[0.2, 0.4, 0.6, 0.8])
    TiO5.append(col)
for col in B_band:
    col = tf.feature_column.bucketized_column(col, boundaries=[0.2, 0.4, 0.6, 0.8])
    B.append(col)
for col in Mgb_band:
    col = tf.feature_column.bucketized_column(col, boundaries=[0.2, 0.4, 0.6, 0.8])
    Mgb.append(col)
for col in CaH_conti:
    col = tf.feature_column.bucketized_column(col, boundaries=[0.2, 0.4, 0.6, 0.8])
    CaH.append(col)
    TiO5.append(col)
    B.append(col)
    Mgb.append(col)

# 矮星亚矮星
# CaOH
CaOH_band = deep_colunms[1229:1240]
CaOH_conti = deep_colunms[1344:1355]
CaOH = []
for col in CaOH_band:
    col = tf.feature_column.bucketized_column(col, boundaries=[0.2, 0.4, 0.6, 0.8])
    CaOH.append(col)
for col in CaOH_conti:
    col = tf.feature_column.bucketized_column(col, boundaries=[0.2, 0.4, 0.6, 0.8])
    CaOH.append(col)

# CaH1
CaH1_band = deep_colunms[1379:1390]
CaH1_conti = deep_colunms[1344:1355]
CaH1_conti.extend(deep_colunms[1409:1420])
CaH1 = []
for col in CaH1_band:
    col = tf.feature_column.bucketized_column(col, boundaries=[0.2, 0.4, 0.6, 0.8])
    CaH1.append(col)
for col in CaH1_conti:
    col = tf.feature_column.bucketized_column(col, boundaries=[0.2, 0.4, 0.6, 0.8])
    CaH1.append(col)

# CaH2、CaH3
CaH2_band = deep_colunms[1813:1846]
CaH3_band = deep_colunms[1959:1990]
CaH2_conti = deep_colunms[2041:2046]
CaH2 = []
CaH3 = []
for col in CaH2_band:
    col = tf.feature_column.bucketized_column(col, boundaries=[0.2, 0.4, 0.6, 0.8])
    CaH2.append(col)
for col in CaH3_band:
    col = tf.feature_column.bucketized_column(col, boundaries=[0.2, 0.4, 0.6, 0.8])
    CaH3.append(col)
for col in CaH2_conti:
    col = tf.feature_column.bucketized_column(col, boundaries=[0.2, 0.4, 0.6, 0.8])
    CaH2.append(col)
    CaH3.append(col)
    TiO5.append(col)

# crossed columns
crossed_columns = [
    # 巨星矮星
    tf.feature_column.crossed_column([col for col in NaIa], hash_bucket_size=2000),
    tf.feature_column.crossed_column([col for col in NaIb], hash_bucket_size=2000),
    tf.feature_column.crossed_column([col for col in KI], hash_bucket_size=2000),
    tf.feature_column.crossed_column([col for col in CaII], hash_bucket_size=2000),
    tf.feature_column.crossed_column([col for col in CaH], hash_bucket_size=2000),
    tf.feature_column.crossed_column([col for col in TiO5], hash_bucket_size=2000),
    tf.feature_column.crossed_column([col for col in B], hash_bucket_size=2000),
    tf.feature_column.crossed_column([col for col in Mgb], hash_bucket_size=2000),
    # 矮星亚矮星
    tf.feature_column.crossed_column([col for col in CaOH], hash_bucket_size=2000),
    tf.feature_column.crossed_column([col for col in CaH1], hash_bucket_size=2000),
    tf.feature_column.crossed_column([col for col in CaH2], hash_bucket_size=2000),
    tf.feature_column.crossed_column([col for col in CaH3], hash_bucket_size=2000),
]

print('------------------ done ----------------------')

print('---------------creating model -----------------')

model_dir = tempfile.mkdtemp(dir=r'F:\tasks\wide_deep\w_d_dir\guangduji\test')
def build_estimator(model_dir):
    """Build an estimator."""
    m = tf.estimator.DNNLinearCombinedClassifier(
        model_dir=model_dir,
        n_classes=3,
        linear_feature_columns=crossed_columns,
        dnn_feature_columns=deep_colunms,
        dnn_optimizer=tf.train.AdamOptimizer(learning_rate=0.001),
        dnn_hidden_units=[100, 50, 50]
    )
    return m


def input_fn(data, labels, num_epochs, shuffle):
  """Input builder function."""
  return tf.estimator.inputs.pandas_input_fn(
      x=data,
      y=labels,
      batch_size=256,
      num_epochs=num_epochs,
      shuffle=shuffle,
      num_threads=1)
print('------------------ done ----------------------')

print('-----------------training ---------------------')
def train_and_eval(model_dir, epoches):
  """Train and evaluate the model."""

  m = build_estimator(model_dir)
  m.train(
      input_fn=input_fn(traindata, trainlabels, num_epochs=epoches, shuffle=True),
  )
  results = m.evaluate(
      input_fn=input_fn(testdata, testlabels, num_epochs=1, shuffle=False),
  )
  pred = m.predict(
      input_fn=input_fn(testdata, testlabels, num_epochs=1, shuffle=False),
  )


  print('model_info: deep-epoch100')
  print("model directory = %s" % model_dir)

  value_pred = []
  for i in pred:
    tmp = i['class_ids']
    value_pred.append(tmp[0])
  print("model directory = %s" % model_dir)

  print("test accuracy：")
  print(metrics.accuracy_score(testlabels, value_pred))
  print('test precision: ')
  print(metrics.precision_score(testlabels, value_pred, average='macro'))
  print('test recall: ')
  print(metrics.recall_score(testlabels, value_pred, average='macro'))

train_and_eval(model_dir, 100)

end = time.process_time()
print("read: %f s" % (end - start))
